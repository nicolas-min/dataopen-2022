# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.7)
train_cl <- subset(iris, split == "TRUE")
test_cl <- subset(iris, split == "FALSE")
# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.1)
# Splitting data into train
# and test data
split <- sample.split(BostonHousing2, SplitRatio = 0.1)
# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.1)
# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.8)
# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.8)
# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.85)
split
split == "TRUE"
?subset
View(train_cl)
train_cl <- subset(iris, split == "TRUE")
test_cl <- subset(iris, split == "FALSE")
# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.99)
train_cl <- subset(iris, split == "TRUE")
test_cl <- subset(iris, split == "FALSE")
# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.99)
train_cl <- subset(iris, split == "TRUE")
test_cl <- subset(iris, split == "FALSE")
# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.8)
train_cl <- subset(iris, split == "TRUE")
test_cl <- subset(iris, split == "FALSE")
# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.9)
# Splitting data into train
# and test data
split <- sample.split(iris, SplitRatio = 0.9)
train_cl <- subset(iris, split == "TRUE")
test_cl <- subset(iris, split == "FALSE")
?sample.split
# Splitting data into train
# and test data
split1<- sample(c(rep(0, 0.7 * nrow(iris)), rep(1, 0.3 * nrow(iris))))
rep(0, 0.7 * nrow(iris)
)
0.7 * nrow(iris)
nrow(iris)
0.72 * nrow(iris)
0.73 * nrow(iris)
# Splitting data into train
# and test data
split1<- sample(c(rep(0, 0.73 * nrow(iris)), rep(1, 0.27 * nrow(iris))))
0.73 * nrow(iris)
rep(0, 0.73 * nrow(iris))
0.73 * nrow(iris)
length(rep(0, 0.73 * nrow(iris)))
# Splitting data into train
# and test data
split1<- sample(c(rep(0, 0.73 * nrow(iris)), rep(1, 0.27 * nrow(iris))))
split1
train_cl <- iris[split1 == 0]
train_cl <- iris[split1 == 0,]
test_cl <- iris[split1 == 1,]
# Splitting data into train
# and test data
training_percent <- 0.78
# Splitting data into train
# and test data
training_percent <- 0.78
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train_cl <- iris[split1 == 0,]
test_cl <- iris[split1 == 1,]
# Splitting data into train
# and test data
training_percent <- 0.99
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train_cl <- iris[split1 == 0,]
test_cl <- iris[split1 == 1,]
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train_cl <- iris[split1 == 0,]
test_cl <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train_cl[, 1:4])
View(train_scale)
mean(train_scale)
?scale
View(train_cl)
# Feature Scaling
train_scale <- scale(train_cl$Sepal.Length)
View(train_scale)
mean(train_scale)
# Feature Scaling
train_scale <- scale(train_cl[, 1:4])
test_scale <- scale(test_cl[, 1:4])
# Fitting Naive Bayes Model
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train_cl)
classifier_cl
# Predicting on test data'
y_pred <- predict(classifier_cl, newdata = test_cl)
# Confusion Matrix
cm <- table(test_cl$Species, y_pred)
cm
y_pred
# Confusion Matrix
cm <- table(test_cl$Species, y_pred)
cm
y_pred==test_cl$Species
sum(y_pred==test_cl$Species)/length(test_cl$Species)
# For implementing random forest algorithm
install.packages("randomForest")
urlPackage <- "https://cran.r-project.org/src/contrib/Archive/randomForest/randomForest_4.6-12.tar.gz"
install.packages(urlPackage, repos=NULL, type="source")
# For implementing random forest algorithm
library("randomForest")
classifier_cl <- naiveBayes(Species ~ .,data = train_cl)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
classifier_RF <- randomForest(x = train_cl[-5], y = train_cl$Species, ntree = 500)
classifier_RF
classifier_cl
y_pred = predict(classifier_RF, newdata = test[-5])
classifier_RF <- randomForest(x = train_cl[-5], y = train_cl$Species, ntree = 500)
#ML
#https://www.geeksforgeeks.org/7-best-r-packages-for-machine-learning/
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test_cl$Species, y_pred_cl)
cm_cl
cm_RF <- table(test_cl$Species, y_pred_RF)
cm_RF
#accuracy
sum(y_pred_cl==test_cl$Species)/length(test_cl$Species)
sum(y_pred_RF==test_cl$Species)/length(test_cl$Species)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
split1
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
# Confusion Matrix
cm_cl <- table(test_cl$Species, y_pred_cl)
cm_cl
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
cm_RF <- table(test_cl$Species, y_pred_RF)
cm_RF
sum(y_pred_RF==test_cl$Species)/length(test_cl$Species)
#accuracy
sum(y_pred_cl==test_cl$Species)/length(test_cl$Species)
cm_cl
cm_RF
#ML
#https://www.geeksforgeeks.org/7-best-r-packages-for-machine-learning/
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test_cl$Species, y_pred_cl)
cm_cl
cm_RF <- table(test_cl$Species, y_pred_RF)
cm_RF
#accuracy
sum(y_pred_cl==test_cl$Species)/length(test_cl$Species)
sum(y_pred_RF==test_cl$Species)/length(test_cl$Species)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test_cl$Species, y_pred_cl)
# Confusion Matrix
cm_cl <- table(test$Species, y_pred_cl)
cm_cl
cm_RF <- table(test$Species, y_pred_RF)
cm_RF
#ML
#https://www.geeksforgeeks.org/7-best-r-packages-for-machine-learning/
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test$Species, y_pred_cl)
cm_cl
cm_RF <- table(test$Species, y_pred_RF)
cm_RF
#accuracy
sum(y_pred_cl==test_cl$Species)/length(test_cl$Species)
sum(y_pred_RF==test_cl$Species)/length(test_cl$Species)
#ML
#https://www.geeksforgeeks.org/7-best-r-packages-for-machine-learning/
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test$Species, y_pred_cl)
cm_cl
cm_RF <- table(test$Species, y_pred_RF)
cm_RF
#accuracy
sum(y_pred_cl==test$Species)/length(test_cl$Species)
sum(y_pred_RF==test$Species)/length(test_cl$Species)
#ML
#https://www.geeksforgeeks.org/7-best-r-packages-for-machine-learning/
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test$Species, y_pred_cl)
cm_cl
cm_RF <- table(test$Species, y_pred_RF)
cm_RF
#accuracy
sum(y_pred_cl==test$Species)/length(test$Species)
sum(y_pred_RF==test$Species)/length(test$Species)
train[5]
##run knn function
classifier_knn <- knn(train[1:4],test[1:4],cl=train[5],k=13)
##load the package class
library(class)
##run knn function
classifier_knn <- knn(train[1:4],test[1:4],cl=train[5],k=13)
train[1:4]
##run knn function
classifier_knn <- knn(train[1:4],test[1:4],cl=train[5],k=13)
##run knn function
classifier_knn <- knn(train,test,cl=train[5],k=13)
##run knn function
classifier_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=13)
train[,5]
classifier_knn
##run knn function
y_pred_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=13)
cm_knn <- table(test$Species,y_pred_knn)
cm_knn
sum(y_pred_knn==test$Species)/length(test$Species)
y_pred_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=1) #no need to 'train'
cm_knn <- table(test$Species,y_pred_knn)
cm_knn
y_pred_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=2) #no need to 'train'
cm_knn <- table(test$Species,y_pred_knn)
cm_knn
library(dplyr)
library(ggplot2)
library(plm)
library(lmtest)
library(maps)
library(here)
library(stringr)
library("randomForest")
library(mlbench)
library(ggplot2)
library(jtools)
library(huxtable)
data(BostonHousing)
#WLS
#stat 230A p195
ols.fit = lm(medv ~ ., data = BostonHousing)
summ(ols.fit)
export_summs(ols.fit, scale = TRUE, to.file = "png", file.name = "sample_reg.png")
#WLS
#stat 230A p195
ols.fit = lm(medv ~ ., data = BostonHousing)
export_summs(ols.fit)
export_summs(ols.fit)
export_summs(ols.fit,to.file = "../plot/docx", file.name = "test.docx")
export_summs(ols.fit,to.file = "docx", file.name = "../plot/test.docx")
export_summs(ols.fit,to.file = "pdf", file.name = "../plot/test.pdf")
export_summs(ols.fit, scale = TRUE, to.file = "pdf", file.name = "../plot/test.pdf")
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
library(class)
y_pred_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=2)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1 - training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
y_pred_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=2) #no need to 'train'
cm_knn <- table(test$Species,y_pred_knn)
cm_knn
#https://www.statology.org/lasso-regression-in-r/
#https://www.pluralsight.com/guides/linear-lasso-and-ridge-regression-with-r
library(glmnet)
?cv.glmnet
#https://www.statology.org/lasso-regression-in-r/
#https://www.pluralsight.com/guides/linear-lasso-and-ridge-regression-with-r
library(glmnet)
y <- mtcars$hp
x <- data.matrix(mtcars[, c('mpg', 'wt', 'drat', 'qsec')])
#perform k-fold cross-validation to find optimal lambda value
#alpha=0: ridge
#alpha=1: lasso
cv_model <- cv.glmnet(x, y, nfolds=10, alpha = 0) #nfolds=10 is default. if you want LOOCV, change to nrow(x)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
log(best_lambda)
#produce plot of test MSE by lambda value
plot(cv_model)
#coef
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
nrow(x)
#perform k-fold cross-validation to find optimal lambda value
#alpha=0: ridge
#alpha=1: lasso
cv_model <- cv.glmnet(x, y, nfolds=nrow(x), alpha = 0) #nfolds=10 is default. if you want LOOCV, change to nrow(x)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
log(best_lambda)
#produce plot of test MSE by lambda value
plot(cv_model)
#coef
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
#perform k-fold cross-validation to find optimal lambda value
#alpha=0: ridge
#alpha=1: lasso
cv_model <- cv.glmnet(x, y, nfolds=nrow(x), alpha = 0) #nfolds=10 is default. if you want LOOCV, change to nrow(x)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
log(best_lambda)
#produce plot of test MSE by lambda value
plot(cv_model)
#perform k-fold cross-validation to find optimal lambda value
#alpha=0: ridge
#alpha=1: lasso
cv_model <- cv.glmnet(x, y, nfolds=nrow(x), alpha = 1) #nfolds=10 is default. if you want LOOCV, change to nrow(x)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
log(best_lambda)
#produce plot of test MSE by lambda value
plot(cv_model)
#coef
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
#perform k-fold cross-validation to find optimal lambda value
#alpha=0: ridge
#alpha=1: lasso
cv_model <- cv.glmnet(x, y, nfolds=10, alpha = 1) #nfolds=10 is default. if you want LOOCV, change to nrow(x)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
log(best_lambda)
#produce plot of test MSE by lambda value
plot(cv_model)
#coef
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
coef(best_model)
?randomForest
