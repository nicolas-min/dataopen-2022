classifier_cl
# Predicting on test data'
y_pred <- predict(classifier_cl, newdata = test_cl)
# Confusion Matrix
cm <- table(test_cl$Species, y_pred)
cm
y_pred
# Confusion Matrix
cm <- table(test_cl$Species, y_pred)
cm
y_pred==test_cl$Species
sum(y_pred==test_cl$Species)/length(test_cl$Species)
# For implementing random forest algorithm
install.packages("randomForest")
urlPackage <- "https://cran.r-project.org/src/contrib/Archive/randomForest/randomForest_4.6-12.tar.gz"
install.packages(urlPackage, repos=NULL, type="source")
# For implementing random forest algorithm
library("randomForest")
classifier_cl <- naiveBayes(Species ~ .,data = train_cl)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
classifier_RF <- randomForest(x = train_cl[-5], y = train_cl$Species, ntree = 500)
classifier_RF
classifier_cl
y_pred = predict(classifier_RF, newdata = test[-5])
classifier_RF <- randomForest(x = train_cl[-5], y = train_cl$Species, ntree = 500)
#ML
#https://www.geeksforgeeks.org/7-best-r-packages-for-machine-learning/
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test_cl$Species, y_pred_cl)
cm_cl
cm_RF <- table(test_cl$Species, y_pred_RF)
cm_RF
#accuracy
sum(y_pred_cl==test_cl$Species)/length(test_cl$Species)
sum(y_pred_RF==test_cl$Species)/length(test_cl$Species)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
split1
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
# Confusion Matrix
cm_cl <- table(test_cl$Species, y_pred_cl)
cm_cl
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
cm_RF <- table(test_cl$Species, y_pred_RF)
cm_RF
sum(y_pred_RF==test_cl$Species)/length(test_cl$Species)
#accuracy
sum(y_pred_cl==test_cl$Species)/length(test_cl$Species)
cm_cl
cm_RF
#ML
#https://www.geeksforgeeks.org/7-best-r-packages-for-machine-learning/
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test_cl$Species, y_pred_cl)
cm_cl
cm_RF <- table(test_cl$Species, y_pred_RF)
cm_RF
#accuracy
sum(y_pred_cl==test_cl$Species)/length(test_cl$Species)
sum(y_pred_RF==test_cl$Species)/length(test_cl$Species)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test_cl$Species, y_pred_cl)
# Confusion Matrix
cm_cl <- table(test$Species, y_pred_cl)
cm_cl
cm_RF <- table(test$Species, y_pred_RF)
cm_RF
#ML
#https://www.geeksforgeeks.org/7-best-r-packages-for-machine-learning/
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test$Species, y_pred_cl)
cm_cl
cm_RF <- table(test$Species, y_pred_RF)
cm_RF
#accuracy
sum(y_pred_cl==test_cl$Species)/length(test_cl$Species)
sum(y_pred_RF==test_cl$Species)/length(test_cl$Species)
#ML
#https://www.geeksforgeeks.org/7-best-r-packages-for-machine-learning/
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test$Species, y_pred_cl)
cm_cl
cm_RF <- table(test$Species, y_pred_RF)
cm_RF
#accuracy
sum(y_pred_cl==test$Species)/length(test_cl$Species)
sum(y_pred_RF==test$Species)/length(test_cl$Species)
#ML
#https://www.geeksforgeeks.org/7-best-r-packages-for-machine-learning/
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1- training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
# Feature Scaling
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
# to training dataset
set.seed(120) # Setting Seed
classifier_cl <- naiveBayes(Species ~ .,data = train)
classifier_RF <- randomForest(x = train[-5], y = train$Species, ntree = 500)
# Predicting on test data
y_pred_cl <- predict(classifier_cl, newdata = test)
y_pred_RF = predict(classifier_RF, newdata = test[-5])
# Confusion Matrix
cm_cl <- table(test$Species, y_pred_cl)
cm_cl
cm_RF <- table(test$Species, y_pred_RF)
cm_RF
#accuracy
sum(y_pred_cl==test$Species)/length(test$Species)
sum(y_pred_RF==test$Species)/length(test$Species)
train[5]
##run knn function
classifier_knn <- knn(train[1:4],test[1:4],cl=train[5],k=13)
##load the package class
library(class)
##run knn function
classifier_knn <- knn(train[1:4],test[1:4],cl=train[5],k=13)
train[1:4]
##run knn function
classifier_knn <- knn(train[1:4],test[1:4],cl=train[5],k=13)
##run knn function
classifier_knn <- knn(train,test,cl=train[5],k=13)
##run knn function
classifier_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=13)
train[,5]
classifier_knn
##run knn function
y_pred_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=13)
cm_knn <- table(test$Species,y_pred_knn)
cm_knn
sum(y_pred_knn==test$Species)/length(test$Species)
y_pred_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=1) #no need to 'train'
cm_knn <- table(test$Species,y_pred_knn)
cm_knn
y_pred_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=2) #no need to 'train'
cm_knn <- table(test$Species,y_pred_knn)
cm_knn
library(dplyr)
library(ggplot2)
library(plm)
library(lmtest)
library(maps)
library(here)
library(stringr)
library("randomForest")
library(mlbench)
library(ggplot2)
library(jtools)
library(huxtable)
data(BostonHousing)
#WLS
#stat 230A p195
ols.fit = lm(medv ~ ., data = BostonHousing)
summ(ols.fit)
export_summs(ols.fit, scale = TRUE, to.file = "png", file.name = "sample_reg.png")
#WLS
#stat 230A p195
ols.fit = lm(medv ~ ., data = BostonHousing)
export_summs(ols.fit)
export_summs(ols.fit)
export_summs(ols.fit,to.file = "../plot/docx", file.name = "test.docx")
export_summs(ols.fit,to.file = "docx", file.name = "../plot/test.docx")
export_summs(ols.fit,to.file = "pdf", file.name = "../plot/test.pdf")
export_summs(ols.fit, scale = TRUE, to.file = "pdf", file.name = "../plot/test.pdf")
data(BostonHousing)
data(BostonHousing2)
data(iris)
# Loading package
library(e1071)
library(caTools)
library(caret)
library(mlbench)
library(class)
y_pred_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=2)
# Splitting data into train
# and test data
training_percent <- 0.75
testing_percent <- 1 - training_percent
split1<- sample(c(rep(0, training_percent * nrow(iris)), rep(1, testing_percent * nrow(iris))))
train <- iris[split1 == 0,]
test <- iris[split1 == 1,]
train_scale <- scale(train[, 1:4])
test_scale <- scale(test[, 1:4])
y_pred_knn <- knn(train[1:4],test[1:4],cl=train[,5],k=2) #no need to 'train'
cm_knn <- table(test$Species,y_pred_knn)
cm_knn
#https://www.statology.org/lasso-regression-in-r/
#https://www.pluralsight.com/guides/linear-lasso-and-ridge-regression-with-r
library(glmnet)
?cv.glmnet
#https://www.statology.org/lasso-regression-in-r/
#https://www.pluralsight.com/guides/linear-lasso-and-ridge-regression-with-r
library(glmnet)
y <- mtcars$hp
x <- data.matrix(mtcars[, c('mpg', 'wt', 'drat', 'qsec')])
#perform k-fold cross-validation to find optimal lambda value
#alpha=0: ridge
#alpha=1: lasso
cv_model <- cv.glmnet(x, y, nfolds=10, alpha = 0) #nfolds=10 is default. if you want LOOCV, change to nrow(x)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
log(best_lambda)
#produce plot of test MSE by lambda value
plot(cv_model)
#coef
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
nrow(x)
#perform k-fold cross-validation to find optimal lambda value
#alpha=0: ridge
#alpha=1: lasso
cv_model <- cv.glmnet(x, y, nfolds=nrow(x), alpha = 0) #nfolds=10 is default. if you want LOOCV, change to nrow(x)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
log(best_lambda)
#produce plot of test MSE by lambda value
plot(cv_model)
#coef
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
#perform k-fold cross-validation to find optimal lambda value
#alpha=0: ridge
#alpha=1: lasso
cv_model <- cv.glmnet(x, y, nfolds=nrow(x), alpha = 0) #nfolds=10 is default. if you want LOOCV, change to nrow(x)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
log(best_lambda)
#produce plot of test MSE by lambda value
plot(cv_model)
#perform k-fold cross-validation to find optimal lambda value
#alpha=0: ridge
#alpha=1: lasso
cv_model <- cv.glmnet(x, y, nfolds=nrow(x), alpha = 1) #nfolds=10 is default. if you want LOOCV, change to nrow(x)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
log(best_lambda)
#produce plot of test MSE by lambda value
plot(cv_model)
#coef
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
#perform k-fold cross-validation to find optimal lambda value
#alpha=0: ridge
#alpha=1: lasso
cv_model <- cv.glmnet(x, y, nfolds=10, alpha = 1) #nfolds=10 is default. if you want LOOCV, change to nrow(x)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
log(best_lambda)
#produce plot of test MSE by lambda value
plot(cv_model)
#coef
best_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)
coef(best_model)
?randomForest
data <- read.csv("../data/diabetic_data.csv")
#1. Ignored the following features: weight and payer code
data_no_weight_pc <- data %>% select(-c(weight, payer_code))
library(dplyr)
library(ggplot2)
library(plm)
library(lmtest)
library(maps)
library(here)
library(stringr)
library("randomForest")
#1. Ignored the following features: weight and payer code
data_no_weight_pc <- data %>% select(-c(weight, payer_code))
View(data_no_weight_pc)
#2. Imputed '?' in medical specialty with "missing"
data_no_weight_pc$medical_specialty[data_no_weight_pc$medical_specialty == "?"] <- "missing"
#3. Kept only the first encounter for each patient.
data_no_weight_pc %>% group_by(patient_nbr) %>% slice(1)
#3. Kept only the first encounter for each patient.
data_first_encounter <- data_no_weight_pc %>% group_by(patient_nbr) %>% slice(1)
library(stringr)
#4. Removed all encounters that resulted in either discharge to a hospice or patient death.
cleaned_data <- data_first_encounter %>% filter(discharge_disposition_id != 13|discharge_disposition_id != 14)
#4. Removed all encounters that resulted in either discharge to a hospice or patient death.
cleaned_data <- data_first_encounter %>% filter(discharge_disposition_id != 13&discharge_disposition_id != 14)
#4. Removed all encounters that resulted in either discharge to a hospice or patient death.
cleaned_data <- data_first_encounter %>% filter(discharge_disposition_id != 13&discharge_disposition_id != 14&discharge_disposition_id != 19&discharge_disposition_id != 20&discharge_disposition_id != 21&discharge_disposition_id != 11)
View(cleaned_data)
#construct binary outcome variable
cleaned_data$readmitted_binary <- NA
#4. Removed all encounters that resulted in either discharge to a hospice or patient death.
cleaned_data <- data_first_encounter %>% filter(discharge_disposition_id != 13&discharge_disposition_id != 14&discharge_disposition_id != 19&discharge_disposition_id != 20&discharge_disposition_id != 21&discharge_disposition_id != 11)
#construct binary outcome variable
cleaned_data$early_readmitted<- NA
#construct binary outcome variable
cleaned_data$early_readmitted<- 0
cleaned_data$early_readmitted[cleaned_data$readmitted == "<30"]
cleaned_data$early_readmitted[cleaned_data$readmitted == "<30"] <- 1
#export
write.csv(cleaned_data, "diabetic_data_prelim_cleaned.csv")
#export
write.csv(cleaned_data, "../data/diabetic_data_prelim_cleaned.csv")
sort(unique(cleaned_data$diag_1))
as.character(seq(390, 459, 1), 785)
#5. Grouped icd9 code
circulatory <- as.character(seq(390, 459, 1), 785)
respiratory <- as.character(seq(460, 519, 1), 786)
circulatory <- as.character(seq(390, 459, 1), 785)
respiratory <- as.character(seq(460, 519, 1), 786)
digestive <- as.character(seq(520, 579, 1), 787)
diabetes <- as.character(seq(250, 250.99, 0.01))
injury <- as.character(seq(800, 999, 1))
musculoskeletal <- as.character(seq(710, 739, 1))
genitourinary <- as.character(seq(580, 629, 1), 788)
neoplasms <- as.character(seq(140, 239, 1), 780,781,784, seq(790, 799, 1),seq(240, 249, 1),seq(251, 279, 1),seq(680, 709, 1),782,seq(1, 139, 1))
neoplasms
cleaned_data$diag_1_grouped <- "Other"
cleaned_data$diag_1
cleaned_data$diag_1 %in% circulatory
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% circulatory] <- "circulatory"
cleaned_data$diag_1_grouped <- "Other"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% circulatory] <- "circulatory"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% respiratory] <- "respiratory"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% digestive] <- "digestive"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% diabetes] <- "diabetes"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% injury] <- "injury"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% musculoskeletal] <- "musculoskeletal"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% genitourinary] <- "genitourinary"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% neoplasms] <- "neoplasms"
summary(cleaned_data$diag_1_grouped)
summary(as.factor(cleaned_data$diag_1_grouped))
summary(as.factor(cleaned_data$diag_1_grouped))/69973
sort(unique(cleaned_data$diag_1))
#1. Ignored the following features: weight and payer code
data_no_weight_pc <- data %>% select(-c(weight, payer_code))
#2. Imputed '?' in medical specialty with "missing"
data_no_weight_pc$medical_specialty[data_no_weight_pc$medical_specialty == "?"] <- "missing"
#3. Kept only the first encounter for each patient.
data_first_encounter <- data_no_weight_pc %>% group_by(patient_nbr) %>% slice(1)
#4. Removed all encounters that resulted in either discharge to a hospice or patient death.
cleaned_data <- data_first_encounter %>% filter(discharge_disposition_id != 13&discharge_disposition_id != 14&discharge_disposition_id != 19&discharge_disposition_id != 20&discharge_disposition_id != 21&discharge_disposition_id != 11)
#5. Grouped icd9 code
circulatory <- as.character(seq(390, 459, 1), 785)
respiratory <- as.character(seq(460, 519, 1), 786)
digestive <- as.character(seq(520, 579, 1), 787)
diabetes <- as.character(seq(250, 250.99, 0.01))
injury <- as.character(seq(800, 999, 1))
musculoskeletal <- as.character(seq(710, 739, 1))
genitourinary <- as.character(seq(580, 629, 1), 788)
neoplasms <- as.character(seq(140, 239, 1), 780,781,784, seq(790, 799, 1),seq(240, 249, 1),seq(251, 279, 1),seq(680, 709, 1),782,seq(1, 139, 1))
cleaned_data$diag_1_grouped <- "Other"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% circulatory] <- "circulatory"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% respiratory] <- "respiratory"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% digestive] <- "digestive"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% diabetes] <- "diabetes"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% injury] <- "injury"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% musculoskeletal] <- "musculoskeletal"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% genitourinary] <- "genitourinary"
cleaned_data$diag_1_grouped[cleaned_data$diag_1 %in% neoplasms] <- "neoplasms"
sort(unique(cleaned_data$diag_1))
summary(as.factor(cleaned_data$diag_1_grouped))/69973
#construct binary outcome variable
cleaned_data$early_readmitted<- 0
cleaned_data$early_readmitted[cleaned_data$readmitted == "<30"] <- 1
#export
write.csv(cleaned_data, "../data/diabetic_data_prelim_cleaned.csv")
summary(as.factor(cleaned_data$early_readmitted))/69973
library(dplyr)
library(ggplot2)
library(plm)
library(lmtest)
library(maps)
library(here)
library(stringr)
library("randomForest")
cleaned_data <- read.csv("../data/diabetic_data_prelim_cleaned.csv")
View(cleaned_data)
